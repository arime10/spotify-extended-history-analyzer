{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09efd6d5",
   "metadata": {},
   "source": [
    "This section scans all Spotify \"Extended Streaming History\" files in the directory, combines them into a single dataset, and performs initial time-based formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14ce7fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 files. Starting the merge process...\n",
      "Success! Combined data saved to 'spotify_full_history_merged.csv'.\n",
      "\n",
      "Preview of the merged dataset:\n",
      "                         ts  master_metadata_track_name  \\\n",
      "0 2016-05-07 11:08:09+00:00                 I'm America   \n",
      "1 2016-05-07 11:08:11+00:00               Coming Around   \n",
      "2 2016-05-07 11:08:11+00:00  A Summer Song - Radio Edit   \n",
      "3 2016-05-07 11:08:14+00:00                     Beggars   \n",
      "4 2016-05-07 11:08:14+00:00                  Sensations   \n",
      "\n",
      "  master_metadata_album_artist_name  \n",
      "0                            Cilver  \n",
      "1                        Andie Case  \n",
      "2                 Conner Youngblood  \n",
      "3                          Krewella  \n",
      "4                            Elohim  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "def merge_spotify_data():\n",
    "    \"\"\"\n",
    "    Finds all Streaming_History_Audio files, combines them,\n",
    "    and performs initial data cleaning and formatting.\n",
    "    \"\"\"\n",
    "    # Step 1: List all relevant JSON files\n",
    "    # We use a pattern to match your Spotify data export naming convention\n",
    "    file_pattern = \"Streaming_History_Audio_*.json\"\n",
    "    files = glob.glob(file_pattern)\n",
    "    \n",
    "    if not files:\n",
    "        print(\"Error: No files found matching the pattern! Please ensure your JSON files are in the same directory.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Found {len(files)} files. Starting the merge process...\")\n",
    "\n",
    "    all_records = []\n",
    "\n",
    "    # Step 2: Read each file and extend the master list\n",
    "    for file in files:\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                all_records.extend(data)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "    # Step 3: Create a Pandas DataFrame\n",
    "    df = pd.DataFrame(all_records)\n",
    "\n",
    "    # Step 4: Format Time Data\n",
    "    # Convert 'ts' (timestamp) column to datetime objects for easy analysis\n",
    "    df['ts'] = pd.to_datetime(df['ts'])\n",
    "    \n",
    "    # Add helper columns for detailed temporal analysis\n",
    "    df['year'] = df['ts'].dt.year\n",
    "    df['month'] = df['ts'].dt.month\n",
    "    df['date_time_formatted'] = df['ts'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "    # Step 5: Initial Cleanup (Optional)\n",
    "    # You can filter out tracks played for less than 30 seconds to remove accidental clicks:\n",
    "    # df = df[df['ms_played'] > 30000]\n",
    "\n",
    "    # Save the combined result as a CSV for backup or Excel use\n",
    "    # 'utf-8-sig' ensures special characters are displayed correctly in Excel\n",
    "    output_filename = \"spotify_full_history_merged.csv\"\n",
    "    df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"Success! Combined data saved to '{output_filename}'.\")\n",
    "    return df\n",
    "\n",
    "# Execute the merge\n",
    "spotify_df = merge_spotify_data()\n",
    "\n",
    "# Preview the data\n",
    "if spotify_df is not None:\n",
    "    print(\"\\nPreview of the merged dataset:\")\n",
    "    display_columns = ['ts', 'master_metadata_track_name', 'master_metadata_album_artist_name']\n",
    "    print(spotify_df[display_columns].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea039de",
   "metadata": {},
   "source": [
    "This script serves as the master coordinator. It automatically detects all Spotify JSON files in your folder, merges them, and generates a comprehensive \"Life-Time Report\" grouped by each year. It provides 4 distinct \"Top 10\" tables for every year found in your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d3a88bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 8 files. Merging data for a full timeline analysis...\n",
      "Awesome! Your yearly music biography has been saved to: Spotify_Full_History_Report.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "\n",
    "def generate_full_history_report(output_file=\"Spotify_Full_History_Report.txt\"):\n",
    "    \"\"\"\n",
    "    Automatically detects all Streaming_History JSON files, merges them,\n",
    "    and creates a year-by-year Top 10 report for songs and artists.\n",
    "    \"\"\"\n",
    "    # 1. Locate all relevant JSON files\n",
    "    files = glob.glob(\"Streaming_History_Audio_*.json\")\n",
    "    if not files:\n",
    "        print(\"Error: No Spotify JSON files found! Please check your directory.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Detected {len(files)} files. Merging data for a full timeline analysis...\")\n",
    "    \n",
    "    combined_records = []\n",
    "    for file in files:\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            combined_records.extend(json.load(f))\n",
    "    \n",
    "    # Create DataFrame and prepare time/cleaning filters\n",
    "    df = pd.DataFrame(combined_records)\n",
    "    df['ts'] = pd.to_datetime(df['ts'])\n",
    "    df['year'] = df['ts'].dt.year\n",
    "    df = df.dropna(subset=['master_metadata_track_name'])\n",
    "    \n",
    "    # Filter: Only keep tracks played for more than 10 seconds\n",
    "    df = df[df['ms_played'] > 10000]\n",
    "\n",
    "    # 2. Generate the comprehensive report\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"{'='*30} SPOTIFY ALL-TIME ANALYSIS (2016-2026) {'='*30}\\n\\n\")\n",
    "        \n",
    "        # Process each year chronologically\n",
    "        years = sorted(df['year'].unique())\n",
    "        \n",
    "        for year in years:\n",
    "            year_df = df[df['year'] == year]\n",
    "            total_min = int(year_df['ms_played'].sum() / (1000 * 60))\n",
    "            total_plays = len(year_df)\n",
    "            \n",
    "            f.write(f\"\\n{'#'*25} YEAR: {year} {'#'*25}\\n\")\n",
    "            f.write(f\"Summary: {total_min:,} minutes listened | {total_plays:,} total plays\\n\")\n",
    "            f.write(f\"{'-'*60}\\n\")\n",
    "\n",
    "            # Helper function to write formatted tables to the text file\n",
    "            def write_table(title, data, metric_name, unit_label):\n",
    "                f.write(f\"\\n[{title}]\\n\")\n",
    "                for i, (index, row) in enumerate(data.iterrows(), 1):\n",
    "                    # Handle multi-index (Song + Artist) or single index (Artist only)\n",
    "                    name = \" - \".join(index) if isinstance(index, tuple) else index\n",
    "                    secondary_label = 'plays' if unit_label == 'min' else 'min'\n",
    "                    f.write(f\"{i}. {name} -> {row[metric_name]} {unit_label} ({row['other']} {secondary_label})\\n\")\n",
    "\n",
    "            # A. Top 10 Songs by Duration\n",
    "            songs_duration = year_df.groupby(['master_metadata_track_name', 'master_metadata_album_artist_name']).agg(\n",
    "                main=('ms_played', lambda x: int(x.sum() / (1000 * 60))), other=('ms_played', 'count')\n",
    "            ).sort_values(by='main', ascending=False).head(10)\n",
    "            write_table(f\"{year} - TOP 10 SONGS BY DURATION\", songs_duration, 'main', 'min')\n",
    "\n",
    "            # B. Top 10 Songs by Play Count\n",
    "            songs_count = year_df.groupby(['master_metadata_track_name', 'master_metadata_album_artist_name']).agg(\n",
    "                main=('ms_played', 'count'), other=('ms_played', lambda x: int(x.sum() / (1000 * 60)))\n",
    "            ).sort_values(by='main', ascending=False).head(10)\n",
    "            write_table(f\"{year} - TOP 10 SONGS BY PLAY COUNT\", songs_count, 'main', 'plays')\n",
    "\n",
    "            # C. Top 10 Artists by Duration\n",
    "            artists_duration = year_df.groupby('master_metadata_album_artist_name').agg(\n",
    "                main=('ms_played', lambda x: int(x.sum() / (1000 * 60))), other=('ms_played', 'count')\n",
    "            ).sort_values(by='main', ascending=False).head(10)\n",
    "            write_table(f\"{year} - TOP 10 ARTISTS BY DURATION\", artists_duration, 'main', 'min')\n",
    "\n",
    "            # D. Top 10 Artists by Play Count\n",
    "            artists_count = year_df.groupby('master_metadata_album_artist_name').agg(\n",
    "                main=('ms_played', 'count'), other=('ms_played', lambda x: int(x.sum() / (1000 * 60)))\n",
    "            ).sort_values(by='main', ascending=False).head(10)\n",
    "            write_table(f\"{year} - TOP 10 ARTISTS BY PLAY COUNT\", artists_count, 'main', 'plays')\n",
    "            \n",
    "            f.write(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "    print(f\"Awesome! Your yearly music biography has been saved to: {output_file}\")\n",
    "\n",
    "# Run the master analysis\n",
    "generate_full_history_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f988fc",
   "metadata": {},
   "source": [
    "This interactive script allows you to focus on a single artist. By typing an artist's name, it scans your entire history and generates a dedicated chronological report showing your top songs by that specific artist for every year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c3c4491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Deep dive report for ariana grande created: ariana_grande_Deep_Dive_Report.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "\n",
    "def generate_artist_specific_report(artist_name):\n",
    "    \"\"\"\n",
    "    Scans all JSON files and creates a detailed year-by-year \n",
    "    report for a specific artist requested by the user.\n",
    "    \"\"\"\n",
    "    # 1. Merge all JSON files\n",
    "    files = glob.glob(\"Streaming_History_Audio_*.json\")\n",
    "    if not files:\n",
    "        print(\"Error: JSON files not found! Ensure the files are in the correct directory.\")\n",
    "        return\n",
    "\n",
    "    all_records = []\n",
    "    for file in files:\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            all_records.extend(json.load(f))\n",
    "    \n",
    "    df = pd.DataFrame(all_records)\n",
    "    df['ts'] = pd.to_datetime(df['ts'])\n",
    "    df['year'] = df['ts'].dt.year\n",
    "    \n",
    "    # 2. Filter data for the specific artist (Case-insensitive)\n",
    "    # The column name in Spotify data is 'master_metadata_album_artist_name'\n",
    "    artist_df = df[df['master_metadata_album_artist_name'].str.lower() == artist_name.lower()].copy()\n",
    "\n",
    "    if artist_df.empty:\n",
    "        print(f\"Error: No data found for artist '{artist_name}'.\")\n",
    "        return\n",
    "\n",
    "    # Create a safe filename for the report\n",
    "    report_filename = f\"{artist_name.replace(' ', '_')}_Deep_Dive_Report.txt\"\n",
    "\n",
    "    # 3. Write the report\n",
    "    with open(report_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"{'='*40}\\n\")\n",
    "        f.write(f\" ARTIST ANALYSIS: {artist_name.upper()}\\n\")\n",
    "        f.write(f\"{'='*40}\\n\\n\")\n",
    "\n",
    "        total_min = int(artist_df['ms_played'].sum() / (1000 * 60))\n",
    "        total_plays = len(artist_df)\n",
    "        f.write(f\"All-Time Total Listening: {total_min:,} minutes\\n\")\n",
    "        f.write(f\"All-Time Total Play Count: {total_plays:,} times\\n\")\n",
    "        f.write(f\"{'-'*40}\\n\")\n",
    "\n",
    "        # Loop through each year the artist was listened to\n",
    "        years = sorted(artist_df['year'].unique())\n",
    "        for year in years:\n",
    "            year_df = artist_df[artist_df['year'] == year]\n",
    "            \n",
    "            f.write(f\"\\n>>>> {year} YEARLY DATA <<<<\\n\")\n",
    "            f.write(f\"Yearly Summary: {int(year_df['ms_played'].sum() / (1000 * 60))} min | {len(year_df)} plays\\n\")\n",
    "            \n",
    "            # Analyze Top 10 songs for that artist in that specific year (by Duration)\n",
    "            song_stats = year_df.groupby('master_metadata_track_name').agg(\n",
    "                min=('ms_played', lambda x: int(x.sum() / (1000 * 60))),\n",
    "                count=('ms_played', 'count')\n",
    "            ).sort_values(by='min', ascending=False).head(10)\n",
    "\n",
    "            f.write(f\"\\n[Top Songs of {year}]\\n\")\n",
    "            for i, (song, row) in enumerate(song_stats.iterrows(), 1):\n",
    "                f.write(f\"{i}. {song} -> {row['min']} min ({row['count']} plays)\\n\")\n",
    "            \n",
    "            f.write(\"-\" * 30 + \"\\n\")\n",
    "\n",
    "    print(f\"Success! Deep dive report for {artist_name} created: {report_filename}\")\n",
    "\n",
    "# --- EXECUTION ---\n",
    "# You can type the exact name of the artist you want to analyze\n",
    "target_artist = input(\"Enter the artist name you want to analyze: \")\n",
    "generate_artist_specific_report(target_artist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3a9338",
   "metadata": {},
   "source": [
    "This script creates a \"Hall of Fame\" report for your entire listening history (from 2016 to present). It identifies the Top 50 Songs based on play count and the Top 50 Artists based on total minutes listened. This is a great way to see which artists truly dominate your long-term listening habits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91424809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging 8 files for the All-Time Hall of Fame analysis...\n",
      "\n",
      "Success! All-time Top 50 report generated: Spotify_All_Time_Top50.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "\n",
    "def generate_all_time_top_50_report(output_file=\"Spotify_All_Time_Top50.txt\"):\n",
    "    \"\"\"\n",
    "    Combines all history files and generates a dual-section report:\n",
    "    1. Top 50 Songs by Play Count\n",
    "    2. Top 50 Artists by Total Duration\n",
    "    \"\"\"\n",
    "    # 1. Locate and merge all JSON files (Audio + Video)\n",
    "    # We include both because some favorite tracks might have been consumed as videos\n",
    "    file_pattern = \"Streaming_History_Audio_*.json\"\n",
    "    files = glob.glob(file_pattern)\n",
    "    \n",
    "    if not files:\n",
    "        print(\"Error: JSON files not found! Ensure your streaming history files are in the directory.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Merging {len(files)} files for the All-Time Hall of Fame analysis...\")\n",
    "    \n",
    "    all_data_list = []\n",
    "    for file in files:\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            all_data_list.extend(json.load(f))\n",
    "    \n",
    "    df = pd.DataFrame(all_data_list)\n",
    "    \n",
    "    # Cleaning: Remove null track names and filter out very short interactions (under 1 second)\n",
    "    df = df.dropna(subset=['master_metadata_track_name'])\n",
    "    df = df[df['ms_played'] > 1000]\n",
    "\n",
    "    # --- ANALYSIS 1: TOP 50 SONGS (BY PLAY COUNT) ---\n",
    "    # This shows which songs you clicked on most frequently\n",
    "    top_50_songs = df.groupby(['master_metadata_track_name', 'master_metadata_album_artist_name']).agg(\n",
    "        count=('ms_played', 'count'),\n",
    "        minutes=('ms_played', lambda x: round(x.sum() / (1000 * 60), 1))\n",
    "    ).sort_values(by='count', ascending=False).head(50)\n",
    "\n",
    "    # --- ANALYSIS 2: TOP 50 ARTISTS (BY TOTAL DURATION) ---\n",
    "    # This shows who you spent the most time listening to\n",
    "    top_50_artists = df.groupby('master_metadata_album_artist_name').agg(\n",
    "        minutes=('ms_played', lambda x: int(x.sum() / (1000 * 60))),\n",
    "        count=('ms_played', 'count')\n",
    "    ).sort_values(by='minutes', ascending=False).head(50)\n",
    "\n",
    "    # 2. Write the Ultimate Report\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"{'='*65}\\n\")\n",
    "        f.write(f\"      SPOTIFY ALL-TIME HALL OF FAME (2016-2026) REPORT\\n\")\n",
    "        f.write(f\"{'='*65}\\n\\n\")\n",
    "\n",
    "        f.write(f\">>> SECTION 1: TOP 50 SONGS BY FREQUENCY (PLAY COUNT)\\n\")\n",
    "        f.write(f\"{'(Which songs did you repeat the most? Total minutes shown in brackets)'}\\n\")\n",
    "        f.write(\"-\" * 65 + \"\\n\")\n",
    "        for i, ((song, artist), row) in enumerate(top_50_songs.iterrows(), 1):\n",
    "            f.write(f\"{i:2d}. {song:.<40} {artist} -> {row['count']} plays ({row['minutes']} min)\\n\")\n",
    "\n",
    "        f.write(\"\\n\\n\")\n",
    "        f.write(f\">>> SECTION 2: TOP 50 ARTISTS BY DURATION (TOTAL TIME)\\n\")\n",
    "        f.write(f\"{'(Who occupied most of your time? Total play counts shown in brackets)'}\\n\")\n",
    "        f.write(\"-\" * 65 + \"\\n\")\n",
    "        for i, (artist, row) in enumerate(top_50_artists.iterrows(), 1):\n",
    "            f.write(f\"{i:2d}. {artist:.<40} {row['minutes']:,} min ({row['count']:,} plays)\\n\")\n",
    "\n",
    "    print(f\"\\nSuccess! All-time Top 50 report generated: {output_file}\")\n",
    "\n",
    "# Execute analysis\n",
    "generate_all_time_top_50_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab37b62",
   "metadata": {},
   "source": [
    "This script acts as a data pipeline that transforms raw Spotify JSON files into a structured .csv dataset. It aggregates your entire listening history, calculating the total play count and total minutes for every unique song. This dataset is perfect for further custom analysis or for use in external tools like Excel and Google Sheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7be2254c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining 9 files into a master dataset...\n",
      "\n",
      "Processing Complete! A master list with 8022 unique songs has been created.\n",
      "Dataset saved as: Spotify_Full_History_Dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "\n",
    "def generate_full_history_csv(output_filename=\"Spotify_Full_History_Dataset.csv\"):\n",
    "    \"\"\"\n",
    "    Finds all Streaming_History JSON files, merges them, cleans the data,\n",
    "    and exports a structured CSV with song names, artists, counts, and minutes.\n",
    "    \"\"\"\n",
    "    # 1. Gather all Spotify JSON history files (Audio and Video)\n",
    "    files = glob.glob(\"Streaming_History_*.json\")\n",
    "    \n",
    "    if not files:\n",
    "        print(\"Error: No JSON files found! Please ensure your history files are in this directory.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Combining {len(files)} files into a master dataset...\")\n",
    "    \n",
    "    combined_data = []\n",
    "    for file in files:\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                combined_data.extend(data)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file}: {e}\")\n",
    "    \n",
    "    # Create the master DataFrame\n",
    "    df = pd.DataFrame(combined_data)\n",
    "    \n",
    "    # 2. Data Cleaning\n",
    "    # Remove records without a track name (like podcast episodes or system errors)\n",
    "    df = df.dropna(subset=['master_metadata_track_name'])\n",
    "    \n",
    "    # Filter out interactions shorter than 1 second (accidental clicks)\n",
    "    df = df[df['ms_played'] > 1000]\n",
    "\n",
    "    # 3. Aggregation and Grouping\n",
    "    # Calculate Play Count (Frequency) and Total Duration (Minutes) per song\n",
    "    dataset_df = df.groupby(['master_metadata_track_name', 'master_metadata_album_artist_name']).agg(\n",
    "        Play_Count=('ms_played', 'count'),\n",
    "        Total_Minutes=('ms_played', lambda x: round(x.sum() / (1000 * 60), 2))\n",
    "    ).reset_index()\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    dataset_df.columns = ['Song_Name', 'Artist_Name', 'Play_Count', 'Total_Minutes']\n",
    "\n",
    "    # Sort by frequency (most played at the top)\n",
    "    dataset_df = dataset_df.sort_values(by='Play_Count', ascending=False)\n",
    "\n",
    "    # 4. Export to CSV\n",
    "    # 'utf-8-sig' is used to ensure special characters (accents, non-latin alphabets) display correctly in Excel\n",
    "    dataset_df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(f\"\\nProcessing Complete! A master list with {len(dataset_df)} unique songs has been created.\")\n",
    "    print(f\"Dataset saved as: {output_filename}\")\n",
    "\n",
    "# Run the dataset generator\n",
    "generate_full_history_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77ada37",
   "metadata": {},
   "source": [
    "This script creates a secondary dataset by filtering out any track played for less than 20 seconds. By removing accidental clicks and skipped tracks, this analysis focuses on the music you actually engaged with. This \"Cleaned\" dataset is the foundation for calculating your Skip Rate and Loyalty Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2029d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging 9 files for the cleaned dataset...\n",
      "\n",
      "Cleanup Complete: Tracks under 20 seconds have been excluded.\n",
      "Total 7079 unique 'meaningfully played' tracks saved.\n",
      "File created: Spotify_Dataset_All_Time_Cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "\n",
    "def generate_cleaned_history_csv(output_filename=\"Spotify_Dataset_All_Time_Cleaned.csv\"):\n",
    "    \"\"\"\n",
    "    Combines all Spotify JSON files but only includes tracks played for \n",
    "    more than 20 seconds to ensure high data quality.\n",
    "    \"\"\"\n",
    "    # 1. Locate all JSON files\n",
    "    files = glob.glob(\"Streaming_History_*.json\")\n",
    "    \n",
    "    if not files:\n",
    "        print(\"Error: No JSON files found! Please check your folder.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Merging {len(files)} files for the cleaned dataset...\")\n",
    "    \n",
    "    all_records = []\n",
    "    for file in files:\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                all_records.extend(data)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file}: {e}\")\n",
    "    \n",
    "    df = pd.DataFrame(all_records)\n",
    "    \n",
    "    # 2. Data Cleaning & High-Quality Filtering\n",
    "    # Remove rows with empty track names\n",
    "    df = df.dropna(subset=['master_metadata_track_name'])\n",
    "    \n",
    "    # Filter: Keep only tracks played for more than 20,000 ms (20 seconds)\n",
    "    # This removes skipped tracks and accidental interactions.\n",
    "    df = df[df['ms_played'] > 20000]\n",
    "\n",
    "    # 3. Aggregation\n",
    "    cleaned_csv_df = df.groupby(['master_metadata_track_name', 'master_metadata_album_artist_name']).agg(\n",
    "        Play_Count=('ms_played', 'count'),\n",
    "        Total_Minutes=('ms_played', lambda x: round(x.sum() / (1000 * 60), 2))\n",
    "    ).reset_index()\n",
    "\n",
    "    cleaned_csv_df.columns = ['Song_Name', 'Artist_Name', 'Play_Count', 'Total_Minutes']\n",
    "\n",
    "    # 4. Sorting\n",
    "    # Sort by actual play count (real engagement)\n",
    "    cleaned_csv_df = cleaned_csv_df.sort_values(by='Play_Count', ascending=False)\n",
    "\n",
    "    # 5. Export to CSV\n",
    "    cleaned_csv_df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(f\"\\nCleanup Complete: Tracks under 20 seconds have been excluded.\")\n",
    "    print(f\"Total {len(cleaned_csv_df)} unique 'meaningfully played' tracks saved.\")\n",
    "    print(f\"File created: {output_filename}\")\n",
    "\n",
    "# Run the high-quality dataset generator\n",
    "generate_cleaned_history_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6fd677",
   "metadata": {},
   "source": [
    "Once you have generated your cleaned dataset, you can use this script to search for specific songs. It calculates the Global Rank of the song based on your total listening history and provides detailed statistics including play count and total minutes spent listening to that specific track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8891a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results found for 'break free':\n",
      "------------------------------------------------------------------------------------------\n",
      "RANK   | SONG NAME                           | ARTIST               | PLAYS    | MINUTES   \n",
      "------------------------------------------------------------------------------------------\n",
      "1      | Break Free                          | Ariana Grande        | 319      | 1006.11   \n",
      "2503   | break free - live                   | Ariana Grande        | 7        | 17.68     \n",
      "4312   | Break Free (feat. Zedd)             | Ariana Grande        | 1        | 3.61      \n",
      "4312   | Break Free (Karaoke Version) [Origi | Zoom Karaoke         | 1        | 0.36      \n",
      "4312   | I Want To Break Free                | Queen                | 1        | 2.26      \n",
      "Exiting search engine...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def search_track():\n",
    "    \"\"\"\n",
    "    Loads the cleaned CSV dataset and allows the user to search for songs\n",
    "    interactively to see their ranking and total stats.\n",
    "    \"\"\"\n",
    "    # 1. Load the cleaned CSV file\n",
    "    try:\n",
    "        df = pd.read_csv(\"Spotify_Dataset_All_Time_Cleaned.csv\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: 'Spotify_Dataset_All_Time_Cleaned.csv' not found. Please run the dataset generator first.\")\n",
    "        return\n",
    "\n",
    "    # 2. Add a Global Rank column based on Play Count\n",
    "    #method='min' ensures that tied counts get the same rank\n",
    "    df['Global_Rank'] = df['Play_Count'].rank(method='min', ascending=False).astype(int)\n",
    "\n",
    "    while True:\n",
    "        query = input(\"\\nEnter the song name you want to search for (Press 'q' to quit): \").strip()\n",
    "        \n",
    "        if query.lower() == 'q':\n",
    "            print(\"Exiting search engine...\")\n",
    "            break\n",
    "        \n",
    "        # 3. Perform the search (Case-insensitive partial match)\n",
    "        results = df[df['Song_Name'].str.contains(query, case=False, na=False)]\n",
    "\n",
    "        if not results.empty:\n",
    "            print(f\"\\nResults found for '{query}':\")\n",
    "            print(\"-\" * 90)\n",
    "            # Formatted column headers\n",
    "            print(f\"{'RANK':<6} | {'SONG NAME':<35} | {'ARTIST':<20} | {'PLAYS':<8} | {'MINUTES':<10}\")\n",
    "            print(\"-\" * 90)\n",
    "            \n",
    "            for _, row in results.iterrows():\n",
    "                # Truncate long names for clean display\n",
    "                song_display = str(row['Song_Name'])[:35]\n",
    "                artist_display = str(row['Artist_Name'])[:20]\n",
    "                \n",
    "                print(f\"{row['Global_Rank']:<6} | {song_display:<35} | {artist_display:<20} | {row['Play_Count']:<8} | {row['Total_Minutes']:<10}\")\n",
    "        else:\n",
    "            print(f\"No results found for '{query}' in your listening history.\")\n",
    "\n",
    "# Initialize the search engine\n",
    "if __name__ == \"__main__\":\n",
    "    search_track()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad586067",
   "metadata": {},
   "source": [
    "This script identifies your \"Stable Favorites.\" It compares the Raw Dataset (all attempts to play a song) with the Cleaned Dataset (meaningful listens over 20 seconds). If a song has a very small difference between these two datasets, it means you almost never skip that song. This is the ultimate metric for identifying the core pillars of your music taste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18ef35ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loyalty analysis complete! Stable favorites saved to: Loyalty_Stability_Report.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generate_loyalty_stability_report(raw_csv=\"Spotify_Full_History_Dataset.csv\", \n",
    "                                     clean_csv=\"Spotify_Dataset_All_Time_Cleaned.csv\",\n",
    "                                     output_file=\"Loyalty_Stability_Report.txt\"):\n",
    "    \"\"\"\n",
    "    Compares raw and cleaned data to identify songs you rarely skip.\n",
    "    Filters: Minimum 50 clean plays and a maximum difference (skip count) of 6.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Load both datasets\n",
    "        df_raw = pd.read_csv(raw_csv)\n",
    "        df_clean = pd.read_csv(clean_csv)\n",
    "\n",
    "        # Rename columns to avoid confusion during merging\n",
    "        df_raw = df_raw.rename(columns={'Play_Count': 'Raw_Plays'})\n",
    "        df_clean = df_clean.rename(columns={'Play_Count': 'Clean_Plays'})\n",
    "\n",
    "        # 2. Merge datasets on Song and Artist name\n",
    "        merged = pd.merge(df_clean[['Song_Name', 'Artist_Name', 'Clean_Plays']], \n",
    "                          df_raw[['Song_Name', 'Artist_Name', 'Raw_Plays']], \n",
    "                          on=['Song_Name', 'Artist_Name'])\n",
    "\n",
    "        # 3. Apply Loyalty Kriterleri\n",
    "        # Difference = Total clicks minus meaningful listens (represents skip count)\n",
    "        merged['Difference'] = merged['Raw_Plays'] - merged['Clean_Plays']\n",
    "        \n",
    "        # Filter: At least 50 meaningful plays and no more than 6 skips/accidental clicks\n",
    "        stability_list = merged[(merged['Clean_Plays'] >= 50) & (merged['Difference'] <= 6)].copy()\n",
    "\n",
    "        # Sort by stability (lowest difference first) then by play count\n",
    "        stability_list = stability_list.sort_values(by=['Difference', 'Clean_Plays'], ascending=[True, False])\n",
    "\n",
    "        # 4. Export the findings to a text file\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"{'='*80}\\n\")\n",
    "            f.write(f\"{'STABLE FAVORITES REPORT (LOYALTY ANALYSIS)':^80}\\n\")\n",
    "            f.write(f\"{'='*80}\\n\\n\")\n",
    "            f.write(\"Analysis Criteria:\\n\")\n",
    "            f.write(\"- Meaningful Plays (Duration > 20s) must be at least 50\\n\")\n",
    "            f.write(\"- Difference between Total Attempts and Real Plays must be <= 6\\n\")\n",
    "            f.write(f\"{'-'*80}\\n\\n\")\n",
    "            \n",
    "            f.write(f\"{'RANK':<5} | {'SONG NAME':<30} | {'ARTIST':<20} | {'CLEAN':<6} | {'DIFF':<5}\\n\")\n",
    "            f.write(f\"{'-'*80}\\n\")\n",
    "\n",
    "            for i, (_, row) in enumerate(stability_list.iterrows(), 1):\n",
    "                song_name = str(row['Song_Name'])[:30]\n",
    "                artist_name = str(row['Artist_Name'])[:20]\n",
    "                f.write(f\"{i:<5} | {song_name:<30} | {artist_name:<20} | {row['Clean_Plays']:<6} | {row['Difference']:<5}\\n\")\n",
    "\n",
    "            f.write(f\"\\n\\nTOTAL {len(stability_list)} STABLE SONGS FOUND.\\n\")\n",
    "\n",
    "        print(f\"Loyalty analysis complete! Stable favorites saved to: {output_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during analysis: {e}\")\n",
    "\n",
    "# Generate the loyalty report\n",
    "generate_loyalty_stability_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2cbcce",
   "metadata": {},
   "source": [
    "This is the most advanced analysis in the toolkit. It calculates a Loyalty Ratio by dividing your total attempts to play a song by your \"meaningful\" listens (more than 20 seconds).\n",
    "\n",
    "A Ratio of 1.00 means you never skipped that song.\n",
    "\n",
    "A higher ratio indicates a high \"Skip Rate,\" suggesting the song might be part of a playlist but often gets skipped. This report helps distinguish between \"background noise\" and your \"true masterpieces.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "474ea0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete! Skip Rate report saved to: Loyalty_Skip_Rate_Report.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generate_skip_rate_report(raw_csv=\"Spotify_Full_History_Dataset.csv\", \n",
    "                              clean_csv=\"Spotify_Dataset_All_Time_Cleaned.csv\",\n",
    "                              output_file=\"Loyalty_Skip_Rate_Report.txt\"):\n",
    "    \"\"\"\n",
    "    Calculates the ratio between total attempts and meaningful plays.\n",
    "    Identifies tracks with the highest retention/loyalty.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Load both datasets\n",
    "        df_raw = pd.read_csv(raw_csv)\n",
    "        df_clean = pd.read_csv(clean_csv)\n",
    "\n",
    "        # Rename columns to differentiate metrics\n",
    "        df_raw = df_raw.rename(columns={'Play_Count': 'Total_Attempts'})\n",
    "        df_clean = df_clean.rename(columns={'Play_Count': 'Clean_Plays'})\n",
    "\n",
    "        # 2. Merge datasets\n",
    "        merged = pd.merge(df_clean[['Song_Name', 'Artist_Name', 'Clean_Plays']], \n",
    "                          df_raw[['Song_Name', 'Artist_Name', 'Total_Attempts']], \n",
    "                          on=['Song_Name', 'Artist_Name'])\n",
    "\n",
    "        # 3. Calculate Ratio and Difference\n",
    "        # Ratio = Total Clicks / Meaningful Plays. 1.00 is a perfect score.\n",
    "        merged['Loyalty_Ratio'] = round(merged['Total_Attempts'] / merged['Clean_Plays'], 2)\n",
    "        merged['Difference'] = merged['Total_Attempts'] - merged['Clean_Plays']\n",
    "\n",
    "        # 4. Apply Filters (Focusing on songs with at least 50 real plays)\n",
    "        loyalty_list = merged[merged['Clean_Plays'] >= 50].copy()\n",
    "\n",
    "        # SORTING: Primary sort by Loyalty Ratio (Ascending), secondary by play count\n",
    "        loyalty_list = loyalty_list.sort_values(by=['Loyalty_Ratio', 'Clean_Plays'], \n",
    "                                                ascending=[True, False])\n",
    "\n",
    "        # 5. Export to Text File\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"{'='*100}\\n\")\n",
    "            f.write(f\"{'LOYALTY & SKIP RATE ANALYSIS (2016-2026)':^100}\\n\")\n",
    "            f.write(f\"{'='*100}\\n\\n\")\n",
    "            f.write(\"Definitions:\\n\")\n",
    "            f.write(\"- RATIO: Total attempts divided by meaningful plays. 1.00 = Perfect (Never skipped).\\n\")\n",
    "            f.write(\"- Analysis limited to songs with more than 50 'meaningful' (20s+) plays.\\n\")\n",
    "            f.write(f\"{'-'*100}\\n\\n\")\n",
    "            \n",
    "            f.write(f\"{'RANK':<5} | {'SONG NAME':<30} | {'ARTIST':<20} | {'CLEAN':<6} | {'RATIO':<6} | {'DIFF':<5}\\n\")\n",
    "            f.write(f\"{'-'*100}\\n\")\n",
    "\n",
    "            for i, (_, row) in enumerate(loyalty_list.iterrows(), 1):\n",
    "                song_name = str(row['Song_Name'])[:30]\n",
    "                artist_name = str(row['Artist_Name'])[:20]\n",
    "                f.write(f\"{i:<5} | {song_name:<30} | {artist_name:<20} | {row['Clean_Plays']:<6} | {row['Loyalty_Ratio']:<6} | {row['Difference']:<5}\\n\")\n",
    "\n",
    "            f.write(f\"\\n\\nTOTAL {len(loyalty_list)} ANALYZED TRACKS FOUND.\\n\")\n",
    "\n",
    "        print(f\"Analysis complete! Skip Rate report saved to: {output_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during ratio analysis: {e}\")\n",
    "\n",
    "# Generate the skip rate report\n",
    "generate_skip_rate_report()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
